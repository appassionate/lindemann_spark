{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7536c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "import sys\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f9a3a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30692ab2",
   "metadata": {},
   "source": [
    "### pyspark 做lindemann分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f730273",
   "metadata": {},
   "source": [
    "此处全部用numpy数组的方式转换成spark RDD对象进行数据的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94aef7c",
   "metadata": {},
   "source": [
    "TODO: 如何使用spark 分布式的读取Numpy数组是可以优化的地方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "391e88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MDAnalysis import Universe\n",
    "import numpy as np\n",
    "from MDAnalysis.lib.distances import distance_array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80737c",
   "metadata": {},
   "source": [
    "请在此处填写需要进行lindemann分析的轨迹文件 和相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_file = \"./pyiron-pos-1.xyz\"\n",
    "ana_range = (0, ) #轨迹的start, stop, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a1fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "8bd22505",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = Universe(\"./pyiron-pos-1.xyz\")\n",
    "uni.transfer_to_memory()\n",
    "positions = uni.trajectory.get_array()\n",
    "positions = positions[:,:40,:] #取前40个原子\n",
    "\n",
    "#截取一下 内部atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5a67004b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7c8e11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71f43b",
   "metadata": {},
   "source": [
    "### 并行化  running welford算法的实现\n",
    "此处主要为RDD数据之间的编排\n",
    "具体算法看map的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f7089851",
   "metadata": {},
   "outputs": [],
   "source": [
    "partion_frames = sc.parallelize(positions, slices).mapPartitions(calc_partion_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ea26bf87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "slices = 10\n",
    "# dist_array = \n",
    "\n",
    "#写成dag\n",
    "\n",
    "#这两个需要提前计算 不能用dag, 使用的广播处理\n",
    "partion_frames = sc.parallelize(positions, slices).mapPartitions(calc_partion_frames).collect()\n",
    "partion_frames_broad = sc.broadcast(partion_frames)\n",
    "partion_frames_agg = [sum(partion_frames_broad.value[:i+1])-1 for i in range(len(partion_frames_broad.value))]\n",
    "partion_frames_agg_broad = sc.broadcast(partion_frames_agg)\n",
    "\n",
    "partion_means = sc.parallelize(positions, slices).mapPartitions(calc_partion_mean)#.collect()\n",
    "partion_vars = sc.parallelize(positions, slices).mapPartitions(calc_partion_var)#.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f004ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#问题变成了 如何低开销的方式获得last_vars和means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2fb0b8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40, 40)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(partion_last_means).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e7b8997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_final_frame(partiondata):\n",
    "    return [partiondata[-1]]\n",
    "partion_means.mapPartitions(slices)\n",
    "\n",
    "partion_last_means = partion_means.mapPartitions(get_final_frame).collect()\n",
    "partion_last_vars = partion_vars.mapPartitions(get_final_frame).collect()\n",
    "\n",
    "partion_last_means_broad = sc.broadcast(partion_last_means)\n",
    "partion_last_vars_broad = sc.broadcast(partion_last_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "1b6573dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "partion_info = partion_means.zip(partion_vars).zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d185e93f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "recovered_means =partion_info.map(\n",
    "    partial(recover_per_mean,\n",
    "            partion_frames_agg_broad=partion_frames_agg_broad, \n",
    "            partion_last_means_broad=partion_last_means_broad,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2f210c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_vars = partion_info.map(partial(recover_per_var, \n",
    "                                     partion_frames_agg_broad=partion_frames_agg_broad, \n",
    "                                     partion_last_means_broad=partion_last_means_broad, \n",
    "                                     partion_last_vars_broad=partion_last_vars_broad))#.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b5de3",
   "metadata": {},
   "source": [
    "### 最终lindex数值的求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "fcf8c646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def get_lindex(zipped_var_mean_idx):\n",
    "    \n",
    "    mean = zipped_var_mean_idx[0][0]\n",
    "    var = zipped_var_mean_idx[0][1]\n",
    "    cur_idx = zipped_var_mean_idx[1]\n",
    "    iframe = cur_idx\n",
    "    \n",
    "    return np.divide(np.sqrt(np.divide(var, iframe)), \n",
    "                             mean)\n",
    "    \n",
    "lindex  = recovered_means.zip(recovered_vars).zipWithIndex().map(get_lindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45291af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lindex.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "e0a285fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "/tmp/ipykernel_1647784/2800759032.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pickle 化数据输出与读取\n",
    "\n",
    "lindex.saveAsPickleFile(\"./lindemann.out\")\n",
    "lindemann_out = sc.pickleFile(\"./lindemann.out/\")\n",
    "lindemann_out.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "dc575db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e079e2e6",
   "metadata": {},
   "source": [
    "#### 一些用于map的函数，请先运行它们"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8b2dff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_per_mean(partion_info, partion_frames_agg_broad, partion_last_means_broad):\n",
    "    \n",
    "    #得到广播的值\n",
    "    partion_frames_agg = partion_frames_agg_broad.value\n",
    "    partion_last_means = partion_last_means_broad.value\n",
    "    \n",
    "    #怎么获取当前帧数的idx?\n",
    "    cur_mean = partion_info[0][0]\n",
    "    cur_idx =  partion_info[1]\n",
    "    \n",
    "    part_idx = sum(np.array(partion_frames_agg)<cur_idx)\n",
    "\n",
    "    whole_true_mean = []\n",
    "    #这两个嵌套 人绕晕了\n",
    "    \n",
    "    latter_tail_mean = partion_last_means[:part_idx]\n",
    "    latter_slice_frames = [item+1 for item in partion_frames_agg[:part_idx]] #idx与 当前帧的数量的区别\n",
    "    latter_frames_sum = int(np.sum(latter_slice_frames))\n",
    "    \n",
    "\n",
    "    #此处应该是处理某一帧中的数据 [atoms, atoms] 形状\n",
    "    #这个指针的还原还是很重要的\n",
    "    k = cur_idx if cur_idx <= partion_frames_agg[0] else cur_idx - partion_frames_agg[part_idx-1]-1\n",
    "#for test\n",
    "#     if cur_idx < 200: \n",
    "#         print(\"cur_idx: \", cur_idx)\n",
    "#         print(\"k: \", k)\n",
    "    cur_frame_nums = latter_frames_sum + (k+1)\n",
    "    sample_len = np.array(latter_slice_frames + [k+1]) #[n1, n2, n3, ... k]\n",
    "    ratio_mean = np.array(latter_slice_frames + [k+1])/cur_frame_nums #[n1, n2, n3, ... k]/(sum(n1+nk-1)+k)\n",
    "\n",
    "    #calc mean\n",
    "    tail_mean = np.array(latter_tail_mean + [cur_mean]) #当前的 完整的分块的mean\n",
    "    true_mean = [tail_mean[idx]*ratio_mean[idx] for idx in range(len(tail_mean))] #shape是什么？ nk个 [[atoms, atoms],[atoms, atoms]]\n",
    "    true_mean = np.sum(true_mean, axis=0) #这里的sum是什么意义？: sum的一些中间量最后的ture_mean的shape还是atoms,atoms\n",
    "    \n",
    "    #print(true_mean.shape)\n",
    "    \n",
    "    return true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e479d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442173f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f1391fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_per_var(partion_info, partion_frames_agg_broad, partion_last_means_broad, partion_last_vars_broad):\n",
    "    \n",
    "    #得到广播的值\n",
    "    partion_frames_agg = partion_frames_agg_broad.value\n",
    "    partion_last_means = partion_last_means_broad.value\n",
    "    partion_last_vars = partion_last_vars_broad.value\n",
    "    \n",
    "    #怎么获取当前帧数的idx?\n",
    "    cur_mean = partion_info[0][0]\n",
    "    cur_var = partion_info[0][1]\n",
    "    cur_idx =  partion_info[1]\n",
    "    \n",
    "    part_idx = sum(np.array(partion_frames_agg)<cur_idx)\n",
    "\n",
    "    whole_true_mean = []\n",
    "    \n",
    "    latter_tail_mean = partion_last_means[:part_idx]\n",
    "    latter_tail_var = partion_last_vars[:part_idx]\n",
    "    latter_slice_frames = [item+1 for item in partion_frames_agg[:part_idx]] #idx与 当前帧的数量的区别\n",
    "    latter_frames_sum = int(np.sum(latter_slice_frames))\n",
    "    \n",
    "\n",
    "    #此处应该是处理某一帧中的数据 [atoms, atoms] 形状\n",
    "    #这个指针的还原还是很重要的\n",
    "    k = cur_idx if cur_idx <= partion_frames_agg[0] else cur_idx - partion_frames_agg[part_idx-1]-1\n",
    "#for test\n",
    "#     if cur_idx < 200: \n",
    "#         print(\"cur_idx: \", cur_idx)\n",
    "#         print(\"k: \", k)\n",
    "    cur_frame_nums = latter_frames_sum + (k+1)\n",
    "    sample_len = np.array(latter_slice_frames + [k+1]) #[n1, n2, n3, ... k]\n",
    "    ratio_mean = np.array(latter_slice_frames + [k+1])/cur_frame_nums #[n1, n2, n3, ... k]/(sum(n1+nk-1)+k)\n",
    "\n",
    "    #calc mean\n",
    "    tail_mean = np.array(latter_tail_mean + [cur_mean]) #当前的 完整的分块的mean\n",
    "    true_mean = [tail_mean[idx]*ratio_mean[idx] for idx in range(len(tail_mean))] #shape是什么？ nk个 [[atoms, atoms],[atoms, atoms]]\n",
    "    true_mean = np.sum(true_mean, axis=0) #这里的sum是什么意义？: sum的一些中间量最后的ture_mean的shape还是atoms,atoms\n",
    "    \n",
    "    #print(true_mean.shape)\n",
    "    \n",
    "    tail_var = np.array(latter_tail_var + [cur_var])    #几个V的求和  和当前的V\n",
    "    tail_unknown_factors = np.r_[np.square(true_mean - tail_mean)[:part_idx], [np.square(true_mean - cur_mean)]]\n",
    "    #val_1 =  np.array([tail_var[idx]*1 for idx in range(len(tail_var))])\n",
    "    val_1 = tail_var\n",
    "    val_1 = np.sum(val_1, axis=0)\n",
    "    val_2 =  np.array([tail_unknown_factors[idx]*sample_len[idx] for idx in range(len(tail_unknown_factors))])\n",
    "    val_2 = sum(val_2, )\n",
    "    true_var = val_1 + val_2 #sum to var\n",
    "    \n",
    "    return true_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022db7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2308d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_mean(part_idx, meanPartion_info, partion_frames_agg_broad, partion_last_means_broad):\n",
    "    \n",
    "    partion_frames_agg = partion_frames_agg_broad.value\n",
    "    partion_last_means = partion_last_means_broad.value\n",
    "    \n",
    "    slice_mean = meanPartion\n",
    "    whole_true_mean = []\n",
    "    #这两个嵌套 人绕晕了\n",
    "    \n",
    "    latter_tail_mean = partion_last_means[:part_idx]\n",
    "    latter_slice_frames = [item+1 for item in partion_frames_agg[:part_idx]] #idx与 当前帧的数量的区别\n",
    "    latter_frames_sum = int(np.sum(latter_slice_frames))\n",
    "    \n",
    "    for k in range(len(slice_mean)): # 一个partion中的mean 的长度 要遍历slice_mean 和slice_var\n",
    "\n",
    "        #此处应该是处理某一帧中的数据 [atoms, atoms] 形状\n",
    "\n",
    "        cur_frame_nums = latter_frames_sum + (k+1)\n",
    "        sample_len = np.array(latter_slice_frames + [k+1]) #[n1, n2, n3, ... k]\n",
    "        ratio_mean = np.array(latter_slice_frames + [k+1])/cur_frame_nums #[n1, n2, n3, ... k]/(sum(n1+nk-1)+k)\n",
    "\n",
    "        #calc mean\n",
    "        tail_mean = np.array(latter_tail_mean + [slice_mean[k]]) #当前的 完整的分块的mean\n",
    "        true_mean = [tail_mean[idx]*ratio_mean[idx] for idx in range(len(tail_mean))] #shape是什么？ nk个 [[atoms, atoms],[atoms, atoms]]\n",
    "        true_mean = np.sum(true_mean, axis=0) #这里的sum是什么意义？: sum的一些中间量最后的ture_mean的shape还是atoms,atoms\n",
    "        \n",
    "        # 得到了这一帧的true mean\n",
    "        whole_true_mean.append(true_mean)\n",
    "    \n",
    "    return whole_true_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec4013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ae1d3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_variance(part_idx, meanPartion, varPartion, partion_frames_agg, partion_last_meansm, partion_last_vars):\n",
    "    \n",
    "    slice_mean = meanPartion\n",
    "    slice_var = varPartion\n",
    "    \n",
    "    whole_true_mean = []\n",
    "    whole_true_var = []\n",
    "    \n",
    "    \n",
    "    latter_tail_mean = partion_last_means[:part_idx]\n",
    "    latter_tail_var = partion_last_vars[:part_idx]\n",
    "    latter_slice_frames = [item+1 for item in partion_frames_agg[:part_idx]] #idx与 当前帧的数量的区别\n",
    "    latter_frames_sum = int(np.sum(latter_slice_frames))\n",
    "    \n",
    "    for k in range(len(slice_mean)): # 一个partion中的mean 的长度 要遍历slice_mean 和slice_var\n",
    "\n",
    "        #此处应该是处理某一帧中的数据 [atoms, atoms] 形状\n",
    "\n",
    "        cur_frame_nums = latter_frames_sum + (k+1)\n",
    "        sample_len = np.array(latter_slice_frames + [k+1]) #[n1, n2, n3, ... k]\n",
    "        ratio_mean = np.array(latter_slice_frames + [k+1])/cur_frame_nums #[n1, n2, n3, ... k]/(sum(n1+nk-1)+k)\n",
    "\n",
    "        #calc mean\n",
    "        tail_mean = np.array(latter_tail_mean + [slice_mean[k]]) #当前的 完整的分块的mean\n",
    "        true_mean = [tail_mean[idx]*ratio_mean[idx] for idx in range(len(tail_mean))] #shape是什么？ nk个 [[atoms, atoms],[atoms, atoms]]\n",
    "        true_mean = np.sum(true_mean, axis=0) #这里的sum是什么意义？: sum的一些中间量最后的ture_mean的shape还是atoms,atoms\n",
    "        # 得到了这一帧的true mean\n",
    "    \n",
    "        tail_var = np.array(latter_tail_var + [slice_var[k]])    #几个V的求和  和当前的V\n",
    "        tail_unknown_factors = np.r_[np.square(true_mean - tail_mean)[:part_idx], [np.square(true_mean - slice_mean[k])]]\n",
    "        #val_1 =  np.array([tail_var[idx]*1 for idx in range(len(tail_var))])\n",
    "        val_1 = tail_var\n",
    "        val_1 = np.sum(val_1, axis=0)\n",
    "        val_2 =  np.array([tail_unknown_factors[idx]*sample_len[idx] for idx in range(len(tail_unknown_factors))])\n",
    "        val_2 = sum(val_2, )\n",
    "        true_var = val_1 + val_2 #sum to var\n",
    "\n",
    "        whole_true_mean.append(true_mean)\n",
    "        whole_true_var.append(true_var)\n",
    "    \n",
    "    return whole_true_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9c97f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_partion_frames(frames):\n",
    "    \n",
    "    return np.array([len(list(frames))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "777804d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_partion_var(frames, box=None):\n",
    "    \n",
    "    #we called frame as (natoms, 3) size then frames will be (n, natoms ,3).\n",
    "    \n",
    "    #迭代器是有一定优化的 解开迭代器会导致什么？\n",
    "    frames = list(frames)\n",
    "    natoms = len(frames[0])\n",
    "    #nframes = len(frames)\n",
    "\n",
    "    # array_distance.shape: (natoms, natoms) far bigger than frames \n",
    "\n",
    "    series_mean = np.empty((0, natoms, natoms), dtype=float)\n",
    "    series_var = np.empty((0, natoms, natoms), dtype=float)\n",
    "\n",
    "    array_mean = np.zeros((natoms, natoms))\n",
    "    array_var = np.zeros((natoms, natoms))\n",
    "    \n",
    "    #print(len(frames))\n",
    "    \n",
    "    for fr_idx, frame in enumerate(frames):\n",
    "        #print(fr_idx)\n",
    "        array_distance = distance_array(frame, frame, box=box)\n",
    "\n",
    "        for i in range(natoms):\n",
    "            for j in range(i + 1, natoms):\n",
    "                xn = array_distance[i, j]\n",
    "                mean = array_mean[i, j]\n",
    "                var = array_var[i, j]\n",
    "                delta = xn - mean\n",
    "                # update mean\n",
    "                array_mean[i, j] = mean + delta / (fr_idx + 1)\n",
    "                # update variance\n",
    "                array_var[i, j] = var + delta * (xn - array_mean[i, j])\n",
    "\n",
    "        for i in range(natoms):\n",
    "            for j in range(i + 1, natoms):\n",
    "                array_mean[j, i] = array_mean[i, j]\n",
    "                array_var[j, i] = array_var[i, j]\n",
    "        \n",
    "            \n",
    "        series_mean = np.r_[series_mean, [array_mean]]\n",
    "        series_var = np.r_[series_var, [array_var]]\n",
    "    \n",
    "    return series_var#, series_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "83c5ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_partion_mean(frames, box=None):\n",
    "    \n",
    "    #we called frame as (natoms, 3) size then frames will be (n, natoms ,3).\n",
    "    \n",
    "    #迭代器是有一定优化的 解开迭代器会导致什么？\n",
    "    frames = list(frames)\n",
    "    natoms = len(frames[0])\n",
    "    #nframes = len(frames)\n",
    "\n",
    "    # array_distance.shape: (natoms, natoms) far bigger than frames \n",
    "\n",
    "    series_mean = np.empty((0, natoms, natoms), dtype=float)\n",
    "    series_var = np.empty((0, natoms, natoms), dtype=float)\n",
    "\n",
    "    array_mean = np.zeros((natoms, natoms))\n",
    "    #array_var = np.zeros((natoms, natoms))\n",
    "    \n",
    "    #print(len(frames))\n",
    "    \n",
    "    for fr_idx, frame in enumerate(frames):\n",
    "        #print(fr_idx)\n",
    "        array_distance = distance_array(frame, frame, box=box)\n",
    "\n",
    "        for i in range(natoms):\n",
    "            for j in range(i + 1, natoms):\n",
    "                xn = array_distance[i, j]\n",
    "                mean = array_mean[i, j]\n",
    "                #var = array_var[i, j]\n",
    "                delta = xn - mean\n",
    "                # update mean\n",
    "                array_mean[i, j] = mean + delta / (fr_idx + 1)\n",
    "                # update variance\n",
    "                #array_var[i, j] = var + delta * (xn - array_mean[i, j])\n",
    "\n",
    "        for i in range(natoms):\n",
    "            for j in range(i + 1, natoms):\n",
    "                array_mean[j, i] = array_mean[i, j]\n",
    "                #array_var[j, i] = array_var[i, j]\n",
    "        \n",
    "            \n",
    "        series_mean = np.r_[series_mean, [array_mean]]\n",
    "        #series_var = np.r_[series_var, [array_var]]\n",
    "\n",
    "    return series_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c4176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
